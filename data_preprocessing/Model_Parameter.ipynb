{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'metric': 'Manhattan', 'n_neighbors': 3},\n",
       " {'metric': 'Manhattan', 'n_neighbors': 5},\n",
       " {'metric': 'Manhattan', 'n_neighbors': 7},\n",
       " {'metric': 'Euclidean', 'n_neighbors': 3},\n",
       " {'metric': 'Euclidean', 'n_neighbors': 5},\n",
       " {'metric': 'Euclidean', 'n_neighbors': 7}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "grid = {\"n_neighbors\": [3, 5, 7],\n",
    "        \"metric\": [\"Manhattan\", \"Euclidean\"]}\n",
    "\n",
    "#ParameterGrid(grid)\n",
    "list(ParameterGrid(grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 함수의 입력으로 사전을 입력받기: **의 사용\n",
    "def f(a, b):\n",
    "    return a + b\n",
    "\n",
    "input_f = {\"a\": 1, \"b\": 2}\n",
    "#input_f = {\"b\": 2, \"a\": 1}\n",
    "f(**input_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그리드 서치 실습 예제\n",
    "\n",
    "\n",
    "- 사용 모델: (1) k-최근접 이웃\n",
    "    - n_neighbors (3, 5, 7)\n",
    "    - metric (euclidean, manhattan)\n",
    "\n",
    "- 사용 모델: (2) 서포트 벡터 머신\n",
    "    - kernel: rbf, linear\n",
    "    - C: 0.1, 1, 10\n",
    "\n",
    "- 평가 척도: F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "X = load_iris()['data'] # feature\n",
    "Y = load_iris()['target'] # label\n",
    "\n",
    "# 학습 데이터와 평가 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 파라미터 그리드 생성\n",
    "param_grid = dict() \n",
    "# 입력: 모델 함수, 출력: 모델의 하이퍼 파라미터 그리드\n",
    "\n",
    "# 모델별 파라미터 그리드 생성\n",
    "param_grid_for_knn = ParameterGrid({\"n_neighbors\": [3, 5, 7],\n",
    "                           \"metric\":['euclidean', 'manhattan']})\n",
    "\n",
    "param_grid_for_svm = ParameterGrid({\"C\": [0.1, 1, 10],\n",
    "                           \"kernel\":['rbf', 'linear']})\n",
    "\n",
    "# 모델 - 하이퍼 파라미터 그리드를 param_grid에 추가\n",
    "param_grid[KNN] = param_grid_for_knn\n",
    "param_grid[SVC] = param_grid_for_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터 튜닝 \n",
    "best_score = -1 # 현재까지 찾은 가장 높은 f1_score (f1 score는 절대 0보다 작을수 없기에, -1로 설정해도 무방)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "for model_func in [KNN, SVC]:\n",
    "    for param in param_grid[model_func]:\n",
    "        model = model_func(**param).fit(Train_X, Train_Y) #사전이라 **\n",
    "        pred_Y = model.predict(Test_X)        \n",
    "        score = f1_score(Test_Y, pred_Y, average = 'micro') # 다중 분류일 때 macro, micro\n",
    "        \n",
    "        if score > best_score: \n",
    "            # 현재 점수가 지금까지 찾은 최고 점수보다 좋으면, 최고 모델, 파라미터, 점수 업데이트\n",
    "            best_model_func = model_func\n",
    "            best_score = score\n",
    "            best_param = param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델: <class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
      "점수: 0.9736842105263158\n",
      "파라미터: {'metric': 'euclidean', 'n_neighbors': 3}\n"
     ]
    }
   ],
   "source": [
    "print(\"모델:\", best_model_func)\n",
    "print(\"점수:\", best_score)\n",
    "print(\"파라미터:\", best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 모델 학습: 전체 X와 전체 Y에 대해.\n",
    "final_model = best_model_func(**best_param).fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 크기에 따른 모델 선택\n",
    "\n",
    "####  특징 개수가 매우 적은 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9568, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(r\"C:\\Users\\Gyu\\Desktop\\mywork\\FastOnline\\Part 3. 지도학습 주요모델 및 개념\\데이터\")\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"Combined_Cycle_Power_Plant.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특징과 라벨 분리\n",
    "X = df.drop('EP', axis = 1)\n",
    "Y = df['EP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor as MLP\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.tree import DecisionTreeRegressor as DTR\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from sklearn.neighbors import KNeighborsRegressor as KNR\n",
    "\n",
    "# 공정한 비교를 위해 전부 default 값을 사용\n",
    "# random_state가 있는 모델은 모두 같은 값으로 설정\n",
    "\n",
    "SVR_model = SVR()\n",
    "MLP_model = MLP(random_state = 100)\n",
    "LR_model = LR()\n",
    "DTR_model = DTR(random_state = 100)\n",
    "RFR_model = RFR(random_state = 100)\n",
    "KNR_model = KNR()\n",
    "\n",
    "model_list = [SVR_model, MLP_model, LR_model, DTR_model, RFR_model, KNR_model]\n",
    "model_name_list = ['SVR', 'MLP', 'LR', 'DTR', 'RFR', 'KNR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR 11.15624063928403\n",
      "MLP 3.9421874629947724\n",
      "LR 3.628251380729045\n",
      "DTR 3.0464405292720267\n",
      "RFR 2.365834244467129\n",
      "KNR 2.9176435395285303\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "for (model, model_name) in zip(model_list, model_name_list):\n",
    "    score = -cross_val_score(model, X, Y, cv = 5, scoring = 'neg_mean_absolute_error').mean() # -MAE이므로 다시 -를 붙인 것\n",
    "    print(model_name, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "변수 타입 확인 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerID           object\n",
       "gender               object\n",
       "SeniorCitizen         int64\n",
       "Partner              object\n",
       "Dependents           object\n",
       "tenure                int64\n",
       "PhoneService         object\n",
       "MultipleLines        object\n",
       "InternetService      object\n",
       "OnlineSecurity       object\n",
       "OnlineBackup         object\n",
       "DeviceProtection     object\n",
       "TechSupport          object\n",
       "StreamingTV          object\n",
       "StreamingMovies      object\n",
       "Contract             object\n",
       "PaperlessBilling     object\n",
       "PaymentMethod        object\n",
       "MonthlyCharges      float64\n",
       "TotalCharges         object\n",
       "Churn                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Telco_churn_prediction.csv\")\n",
    "df.infer_objects().dtypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ' ']\n"
     ]
    }
   ],
   "source": [
    "def find_str_element(val):\n",
    "    try:\n",
    "        float(val) # 만약 val이 문자라면 여기서 오류가 발생할 것이므로 except로 넘어감\n",
    "        return False\n",
    "    except:\n",
    "        return True\n",
    "\n",
    "# 공백이 섞여 있음을 확인\n",
    "# apply 함수는 자주 사용되는 굉장히 중요한 함수이므로 반드시 숙지해야 함\n",
    "# apply 함수는 각 요소에 함수를 일괄 적용하는 함수임\n",
    "print(df['TotalCharges'][df['TotalCharges'].apply(find_str_element)].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerID          7043\n",
       "gender                 2\n",
       "SeniorCitizen          2\n",
       "Partner                2\n",
       "Dependents             2\n",
       "tenure                73\n",
       "PhoneService           2\n",
       "MultipleLines          3\n",
       "InternetService        3\n",
       "OnlineSecurity         3\n",
       "OnlineBackup           3\n",
       "DeviceProtection       3\n",
       "TechSupport            3\n",
       "StreamingTV            3\n",
       "StreamingMovies        3\n",
       "Contract               3\n",
       "PaperlessBilling       2\n",
       "PaymentMethod          4\n",
       "MonthlyCharges      1585\n",
       "TotalCharges        6531\n",
       "Churn                  2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getting_unique_val(col):\n",
    "    return len(col.unique())\n",
    "\n",
    "df.apply(getting_unique_val, axis = 0) \n",
    "# 유니크한 값 개수 기준으로 판단\n",
    "# 일반적으로 그 개수가 많으면 연속형, 그렇지 않으면 범주형인 경우가 대다수 (ID 관련 컬럼 제외)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "혼합형 변수가 존재하는 경우\n",
    "- 회귀, 나이브 베이즈, knn은 적합 하지 않은 편\n",
    "\n",
    "---\n",
    "\n",
    "### 복잡도 파라미터 튜닝\n",
    "\n",
    "all model\n",
    "- max_iter : 복잡한 모델을 학습할 때 일부러 작게 잡아 과적합을 회피하기도 함\n",
    "\n",
    "정규화 회귀\n",
    "- alpha : 복잡도와 반비례\n",
    "\n",
    "의사 결정 나무\n",
    "- max_depth : 복잡도와 정비례\n",
    "- min_samples_leaf : 복잡도와 반비례\n",
    "\n",
    "SVM\n",
    "- C, gamma, degree : 복잡도와 약한 정비례\n",
    "- kernel : poly > rbf > linear 순으로 과적합 가능성 \n",
    "\n",
    "로지스틱\n",
    "- C : 복잡도와 반비례\n",
    "\n",
    "SVR\n",
    "- epsilon : 복잡도와 강한 정비례\n",
    "\n",
    "Tree Ensemble\n",
    "- max_depth : 복잡도와 정비례지만 과적합 피하기 위해 보통 4이하 설정\n",
    "- learning rate(rf 제외) : 복잡도와 정비례\n",
    "\n",
    "<br>\n",
    "\n",
    "초기값의 영향이 매우 크므로, **seed 고정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Sonar_Mines_Rocks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Y', axis = 1)\n",
    "Y = df['Y']\n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Y.replace({\"M\":-1, \"R\":1}, inplace = True)\n",
    "Test_Y.replace({\"M\":-1, \"R\":1}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 1. 복잡도 파라미터가 한 개이면서, 단순하고, 우연성이 어느정도 있는 모델 (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.1:\t0.5581395348837209\n",
      "C = 1:\t0.7307692307692308\n",
      "C = 5:\t0.7692307692307692\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "\n",
    "def LR_model_test(C):\n",
    "    model = LR(C = C, max_iter = 100000, random_state = 10).fit(Train_X, Train_Y) # 가벼운 모델이므로 max_iter를 크게 잡음\n",
    "    pred_Y = model.predict(Test_X)\n",
    "    return f1_score(Test_Y, pred_Y)\n",
    "\n",
    "print(\"C = 0.1:\\t{}\".format(LR_model_test(C = 0.1)))\n",
    "print(\"C = 1:\\t{}\".format(LR_model_test(C = 1))) \n",
    "print(\"C = 5:\\t{}\".format(LR_model_test(C = 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.6510204081632653, 'max_iter': 100000, 'random_state': 10} 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "# 아직 범위가 넓어 더 탐색\n",
    "import numpy as np\n",
    "LR_parameter_grid = ParameterGrid({\"C\":np.linspace(0.1, 2, 50),\n",
    "                                  \"max_iter\":[100000],\n",
    "                                  \"random_state\":[10]})\n",
    "\n",
    "# 파라미터 튜닝 수행 \n",
    "best_score = -1\n",
    "for parameter in LR_parameter_grid:\n",
    "    model = LR(**parameter).fit(Train_X, Train_Y)\n",
    "    pred_Y = model.predict(Test_X)\n",
    "    score = f1_score(Test_Y, pred_Y)\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_parameter = parameter\n",
    "\n",
    "print(best_parameter, best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 2. 복잡도 파라미터가 두 개이면서, 단순하고, 우연성이 거의 없는 모델 (Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-1:0.7272727272727273\n",
      "3-2:0.7272727272727273\n",
      "3-3:0.7272727272727273\n",
      "6-1:0.75\n",
      "6-2:0.7169811320754716\n",
      "6-3:0.6909090909090909\n",
      "9-1:0.7796610169491525\n",
      "9-2:0.7142857142857143\n",
      "9-3:0.7037037037037037\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "\n",
    "def DTC_model_test(max_depth, min_samples_leaf):\n",
    "    model = DTC(max_depth = max_depth, min_samples_leaf = min_samples_leaf).fit(Train_X, Train_Y) \n",
    "    pred_Y = model.predict(Test_X)\n",
    "    return f1_score(Test_Y, pred_Y) \n",
    "\n",
    "for max_depth in [3, 6, 9]:\n",
    "    for min_samples_leaf in [1, 2, 3]:\n",
    "        score = DTC_model_test(max_depth = max_depth, min_samples_leaf = min_samples_leaf)\n",
    "        print(\"{}-{}:{}\".format(max_depth, min_samples_leaf, score))\n",
    "\n",
    "# max depth가 크고 (복잡도 증가) min_samples_leaf가 큰 경우 (복잡도 감소) 좋은 성능이 나옴을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 8, 'min_samples_leaf': 2} 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 그리드 설정\n",
    "DTC_parameter_grid = ParameterGrid({\"max_depth\": np.arange(6, 15),\n",
    "                                  \"min_samples_leaf\": np.arange(2, 5)})\n",
    "\n",
    "# 파라미터 튜닝 수행 \n",
    "best_score = -1\n",
    "for parameter in DTC_parameter_grid:\n",
    "    model = DTC(**parameter).fit(Train_X, Train_Y)\n",
    "    pred_Y = model.predict(Test_X)\n",
    "    score = f1_score(Test_Y, pred_Y)\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_parameter = parameter\n",
    "\n",
    "print(best_parameter, best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37] *",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
